# 1.1 环境准备操作文档

本文档提供 Istio 环境搭建的详细操作步骤，用于 Sealos Ingress 到 Istio Gateway/VirtualService 迁移。

## 前置要求

- Kubernetes 集群版本 >= 1.27
- kubectl 已配置并能访问集群
- Helm 3.x 已安装
- 集群节点资源充足（每节点至少 4GB 可用内存）

## 1. 部署 Istio 到测试集群

### 1.1 下载并安装 Istioctl

```bash
# 下载 Istio 1.20.x (最新稳定版)
curl -L https://istio.io/downloadIstio | ISTIO_VERSION=1.20.2 sh -

# 添加 istioctl 到 PATH
cd istio-1.20.2
export PATH=$PWD/bin:$PATH

# 验证安装
istioctl version --remote=false
```

### 1.2 安装 Istio 核心组件

创建 Istio 配置文件 `istio-install-config.yaml`：

```yaml
apiVersion: install.istio.io/v1alpha1
kind: IstioOperator
metadata:
  name: sealos-istio
spec:
  # 使用生产配置文件作为基础
  profile: production
  
  # 组件配置
  components:
    ingressGateways:
    - name: istio-ingressgateway
      enabled: true
      k8s:
        resources:
          requests:
            cpu: 1000m
            memory: 1024Mi
          limits:
            cpu: 2000m
            memory: 2048Mi
        service:
          type: LoadBalancer
          ports:
          - port: 15021
            targetPort: 15021
            name: status-port
          - port: 80
            targetPort: 8080
            name: http2
          - port: 443
            targetPort: 8443
            name: https
          - port: 31400
            targetPort: 31400
            name: tcp
        hpaSpec:
          minReplicas: 2
          maxReplicas: 10
          metrics:
          - type: Resource
            resource:
              name: cpu
              target:
                type: Utilization
                averageUtilization: 80
    
    pilot:
      enabled: true
      k8s:
        resources:
          requests:
            cpu: 500m
            memory: 2048Mi
        hpaSpec:
          minReplicas: 2
          maxReplicas: 5
  
  # 网格配置
  meshConfig:
    accessLogFile: /dev/stdout
    defaultConfig:
      proxyStatsMatcher:
        inclusionRegexps:
        - ".*outlier_detection.*"
        - ".*circuit_breakers.*"
        - ".*_rq_retry.*"
        - ".*_rq_pending.*"
        - ".*_cx_.*"
    extensionProviders:
    - name: prometheus
      prometheus:
        service: prometheus.istio-system.svc.cluster.local
        port: 9090
  
  # 全局配置
  values:
    global:
      proxy:
        # 启用自动注入
        autoInject: enabled
        # 资源限制
        resources:
          requests:
            cpu: 100m
            memory: 128Mi
          limits:
            cpu: 2000m
            memory: 1024Mi
      # 多集群配置预留
      multiCluster:
        clusterName: sealos-cluster
    telemetry:
      v2:
        prometheus:
          configOverride:
            inboundSidecar:
              disable_host_header_fallback: true
            outboundSidecar:
              disable_host_header_fallback: true
```

执行安装：

```bash
# 创建 istio-system 命名空间
kubectl create namespace istio-system

# 安装 Istio
istioctl install -f istio-install-config.yaml -y

# 等待所有组件就绪
kubectl -n istio-system wait --for=condition=Ready pod --all --timeout=300s

# 验证安装
istioctl verify-install
```

### 1.3 安装可观测性组件（可选但推荐）

```bash
# 安装 Prometheus
kubectl apply -f https://raw.githubusercontent.com/istio/istio/release-1.20/samples/addons/prometheus.yaml

# 安装 Grafana
kubectl apply -f https://raw.githubusercontent.com/istio/istio/release-1.20/samples/addons/grafana.yaml

# 安装 Kiali
kubectl apply -f https://raw.githubusercontent.com/istio/istio/release-1.20/samples/addons/kiali.yaml

# 安装 Jaeger
kubectl apply -f https://raw.githubusercontent.com/istio/istio/release-1.20/samples/addons/jaeger.yaml

# 等待部署完成
kubectl -n istio-system rollout status deployment/kiali
kubectl -n istio-system rollout status deployment/prometheus
kubectl -n istio-system rollout status deployment/grafana
```

## 2. 配置 Istio 多租户支持

### 2.1 创建多租户 RBAC 策略

创建 `istio-multitenancy-rbac.yaml`：

```yaml
# 为每个租户命名空间创建 ServiceRole
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: istio-namespace-gateway-admin
rules:
- apiGroups: ["networking.istio.io"]
  resources: ["virtualservices", "destinationrules", "serviceentries"]
  verbs: ["*"]
- apiGroups: ["networking.istio.io"]
  resources: ["gateways"]
  verbs: ["get", "list", "watch"]  # 租户只能查看 Gateway，不能修改
---
# 限制跨命名空间流量的 PeerAuthentication
apiVersion: security.istio.io/v1beta1
kind: PeerAuthentication
metadata:
  name: default
  namespace: istio-system
spec:
  mtls:
    mode: STRICT
---
# 默认拒绝所有跨命名空间流量的 AuthorizationPolicy
apiVersion: security.istio.io/v1beta1
kind: AuthorizationPolicy
metadata:
  name: deny-all-cross-namespace
  namespace: istio-system
spec:
  rules:
  - from:
    - source:
        notNamespaces: ["istio-system", "kube-system"]
    to:
    - operation:
        notNamespaces: ["{{ .SourceNamespace }}"]
  action: DENY
```

### 2.2 创建租户命名空间模板

创建脚本 `create-tenant-namespace.sh`：

```bash
#!/bin/bash

TENANT_NAME=$1
NAMESPACE="ns-${TENANT_NAME}"

if [ -z "$TENANT_NAME" ]; then
    echo "Usage: $0 <tenant-name>"
    exit 1
fi

# 创建命名空间
kubectl create namespace $NAMESPACE

# 标记命名空间启用 Istio 注入
kubectl label namespace $NAMESPACE istio-injection=enabled

# 创建租户专用的 Gateway
cat <<EOF | kubectl apply -f -
apiVersion: networking.istio.io/v1beta1
kind: Gateway
metadata:
  name: ${TENANT_NAME}-gateway
  namespace: $NAMESPACE
spec:
  selector:
    istio: ingressgateway
  servers:
  - port:
      number: 80
      name: http
      protocol: HTTP
    hosts:
    - "*.${TENANT_NAME}.sealos.io"
    - "${TENANT_NAME}.sealos.io"
  - port:
      number: 443
      name: https
      protocol: HTTPS
    hosts:
    - "*.${TENANT_NAME}.sealos.io"
    - "${TENANT_NAME}.sealos.io"
    tls:
      mode: SIMPLE
      credentialName: ${TENANT_NAME}-tls-cert
EOF

# 创建命名空间内的流量策略
cat <<EOF | kubectl apply -f -
apiVersion: security.istio.io/v1beta1
kind: AuthorizationPolicy
metadata:
  name: allow-same-namespace
  namespace: $NAMESPACE
spec:
  action: ALLOW
  rules:
  - from:
    - source:
        namespaces: ["$NAMESPACE"]
  - from:
    - source:
        namespaces: ["istio-system"]
---
apiVersion: security.istio.io/v1beta1
kind: AuthorizationPolicy
metadata:
  name: allow-ingress-gateway
  namespace: $NAMESPACE
spec:
  action: ALLOW
  rules:
  - from:
    - source:
        principals: ["cluster.local/ns/istio-system/sa/istio-ingressgateway-service-account"]
EOF

# 应用资源配额（可选）
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: ResourceQuota
metadata:
  name: ${TENANT_NAME}-quota
  namespace: $NAMESPACE
spec:
  hard:
    requests.cpu: "10"
    requests.memory: 20Gi
    persistentvolumeclaims: "10"
    services.loadbalancers: "0"  # 禁止租户创建 LoadBalancer
EOF

echo "Tenant namespace $NAMESPACE created successfully!"
```

使用脚本创建测试租户：

```bash
chmod +x create-tenant-namespace.sh
./create-tenant-namespace.sh user1
./create-tenant-namespace.sh user2
```

## 3. 验证 Istio 与现有组件兼容性

### 3.1 测试与现有 CRD 的兼容性

```bash
# 检查是否有冲突的 CRD
kubectl get crd | grep -E "(virtualservice|gateway|destinationrule)"

# 列出现有的 webhook 配置
kubectl get validatingwebhookconfigurations
kubectl get mutatingwebhookconfigurations

# 确保没有端口冲突
kubectl get svc -A | grep -E "(80|443|15000|15001|15006|15008|15020|15021|15090)"
```

### 3.2 测试基础连通性

创建测试应用 `test-app.yaml`：

```yaml
apiVersion: v1
kind: Service
metadata:
  name: httpbin
  namespace: ns-user1
  labels:
    app: httpbin
spec:
  ports:
  - name: http
    port: 8000
    targetPort: 80
  selector:
    app: httpbin
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: httpbin
  namespace: ns-user1
spec:
  replicas: 1
  selector:
    matchLabels:
      app: httpbin
  template:
    metadata:
      labels:
        app: httpbin
    spec:
      containers:
      - image: docker.io/kennethreitz/httpbin
        imagePullPolicy: IfNotPresent
        name: httpbin
        ports:
        - containerPort: 80
---
apiVersion: networking.istio.io/v1beta1
kind: VirtualService
metadata:
  name: httpbin
  namespace: ns-user1
spec:
  hosts:
  - httpbin.user1.sealos.io
  gateways:
  - user1-gateway
  http:
  - match:
    - uri:
        prefix: /
    route:
    - destination:
        host: httpbin
        port:
          number: 8000
```

部署并测试：

```bash
# 部署测试应用
kubectl apply -f test-app.yaml

# 获取 Ingress Gateway 的外部 IP
export INGRESS_HOST=$(kubectl -n istio-system get service istio-ingressgateway -o jsonpath='{.status.loadBalancer.ingress[0].ip}')
export INGRESS_PORT=$(kubectl -n istio-system get service istio-ingressgateway -o jsonpath='{.spec.ports[?(@.name=="http2")].port}')

# 测试访问（需要配置 DNS 或使用 curl 的 --resolve）
curl -I -HHost:httpbin.user1.sealos.io http://$INGRESS_HOST:$INGRESS_PORT/status/200

# 查看 Envoy 访问日志
kubectl logs -n istio-system -l istio=ingressgateway -c istio-proxy --tail=10
```

### 3.3 验证与 Sealos 控制器的兼容性

```bash
# 检查 Sealos 控制器是否正常运行
kubectl get pods -n sealos-system

# 创建测试用的 Terminal CR
cat <<EOF | kubectl apply -f -
apiVersion: terminal.sealos.io/v1
kind: Terminal
metadata:
  name: test-terminal
  namespace: ns-user1
spec:
  user: user1
  token: test-token
  apiServer: https://kubernetes.default.svc.cluster.local:443
EOF

# 观察控制器日志，确保没有错误
kubectl logs -n sealos-system -l app=terminal-controller --tail=20
```

## 4. 性能基准测试

### 4.1 安装性能测试工具

```bash
# 安装 fortio（Istio 官方推荐的负载测试工具）
kubectl apply -f - <<EOF
apiVersion: v1
kind: Service
metadata:
  name: fortio
  namespace: istio-system
spec:
  ports:
  - port: 8080
    name: http
  selector:
    app: fortio
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: fortio
  namespace: istio-system
spec:
  replicas: 1
  selector:
    matchLabels:
      app: fortio
  template:
    metadata:
      labels:
        app: fortio
    spec:
      containers:
      - name: fortio
        image: fortio/fortio:latest
        ports:
        - containerPort: 8080
        args:
        - server
EOF
```

### 4.2 执行基准测试

```bash
# 进入 fortio pod
kubectl exec -it -n istio-system deployment/fortio -- /bin/bash

# 测试无 Istio 的性能（直接访问服务）
fortio load -c 10 -qps 1000 -t 30s http://httpbin.ns-user1:8000/status/200

# 测试通过 Istio Gateway 的性能
fortio load -c 10 -qps 1000 -t 30s -H "Host: httpbin.user1.sealos.io" http://istio-ingressgateway.istio-system/status/200

# 记录并对比结果
```

### 4.3 监控资源使用

```bash
# 监控 Istio 组件资源使用
kubectl top pods -n istio-system

# 监控 sidecar 注入后的应用资源使用
kubectl top pods -n ns-user1

# 查看 Prometheus 指标（如果已安装）
kubectl port-forward -n istio-system svc/prometheus 9090:9090
# 访问 http://localhost:9090，查询 Istio 相关指标
```

## 5. 故障排查命令

```bash
# 检查 Istio 配置状态
istioctl analyze --all-namespaces

# 查看 Envoy 配置
istioctl proxy-config cluster -n ns-user1 deployment/httpbin
istioctl proxy-config route -n ns-user1 deployment/httpbin

# 查看 Envoy 统计信息
istioctl proxy-stats -n ns-user1 deployment/httpbin

# 调试流量路由
istioctl x describe pod -n ns-user1 httpbin-xxx

# 检查 mTLS 状态
istioctl authn tls-check -n ns-user1 httpbin.ns-user1.svc.cluster.local
```

## 6. 清理测试环境（可选）

```bash
# 删除测试应用
kubectl delete -f test-app.yaml
kubectl delete namespace ns-user1 ns-user2

# 卸载 Istio（谨慎操作）
istioctl uninstall --purge -y
kubectl delete namespace istio-system
```

## 注意事项

1. **资源需求**：Istio 会为每个 Pod 注入 sidecar 代理，预计每个 Pod 额外需要 100MB 内存和 100m CPU
2. **网络策略**：确保集群网络插件支持 NetworkPolicy
3. **负载均衡器**：确保云平台或裸机环境支持 LoadBalancer 类型的 Service
4. **DNS 配置**：需要配置通配符 DNS 记录指向 Istio Ingress Gateway 的外部 IP
5. **证书管理**：生产环境建议集成 cert-manager 自动管理 TLS 证书

## 下一步

完成环境准备后，可以继续进行：
- 1.2 技术方案设计
- 1.3 工具开发